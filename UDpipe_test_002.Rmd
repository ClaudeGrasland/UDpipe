---
title: "Multilanguage annotation with UDpipe"
subtitle: "Parsing time"
author: "Claude Grasland"
output: html_notebook
---

## Introduction

The aim of this short note is to test the time of parsing



## Install the package

Contrary to Spacyr, phe R package UDpipe does not implies a connection with Python and can work directly after installation.

```{r}
#install.package(udpipe)
library(udpipe)
library(knitr)
library(data.table)
```


## Load dataset


Our test dataset is a set of 188773 news published by the daily newspaper Le Monde between mid 2013 and mid 2020 through his RSS flow and collected by Mediacloud : 


```{r}
test<-readRDS("UDpipe/df_fr_FRA_lmonde.RDS")
kable(head(test))

```

## fusion of title and description

We create a column of text called "news" where we add Title and description

```{r}
test$news <- paste(test$title, test$text, sep=". ")
kable(test$news[1])
head(test$news)
```



## Parse text with universal dependencies



## Load french parsing model

we load the default french parsing model

```{r}
sel<-test[test$lang=="fr",]
dl <- udpipe_download_model(language="french")
ud_model_fr<-udpipe_load_model(file=dl$file)
```

## Parse

## principle

We proceed to a full parsing of the news and we add the metadata related to source and time

```{r}
k<-1
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
data.table(res)
```
## Check time for 100 news


```{r}
t1<-Sys.time()
k<-100
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
t2<-Sys.time()

paste("Job done in ",t2-t1)
```

Apparently 3 seconds

## Check time for 1000 news


```{r}
t1<-Sys.time()
k<-1000
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
t2<-Sys.time()

paste("Job done in ",t2-t1)
```


Work done in 27 seconds

## Check time for 10000 news


```{r}
t1<-Sys.time()
k<-10000
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
t2<-Sys.time()

paste("Job done in ",t2-t1)

```

Work done in 4.58 minutes (275 seconds) which means that the processing of news (generally two sentences in the case of Le Monde) is done at the speed of 36 news per seconds or 72 sentences / second.
We can therefore estimate the full time necessary for the sample of Le Monde (188773 news) at 7260 seconds which means 121 minutes or 2 hours approximately.  So let's try now. Its 10:00 and we expect the resuts around noun.

## Check time for the full corpus of 188773 news

```{r}
t1<-Sys.time()
k<-dim(test)[1]
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
t2<-Sys.time()

paste("Job done in ",t2-t1)

```

Le calcul a été efffectué en 1.52 heures soit un peu moins que prévu. Le fichier contient 7.6 millions de lignes (tokens). On sauvegarde évidemment le résultat précieusement, ce qui fait un fichier compressé d'environ 67 Mo au format .RDS.

```{r}
saveRDS(res,"UDpipe/lmonde_2013_2020_parsed")
```


## Réplication sur Libération (116327 news)

On prend un fichier de taille un peu plus petite (Libération) et on recommence (pendant la pause déjeuner).

```{r}
test<-readRDS("UDpipe/df_fr_FRA_libera.RDS")
test$news <- paste(test$title, test$text, sep=". ")
t1<-Sys.time()
k<-dim(test)[1]
sel<-test[1:k,]
meta<-data.frame(doc_id=sel$id,source=sel$source,date=sel$date)
res<-udpipe_annotate(ud_model_fr, x=sel$news,doc_id=sel$id )
res<-as.data.frame(res)[,c(1,3,5:8,10:12)]
res<-merge(meta,res,all.x=F,all.y=T,by="doc_id")
t2<-Sys.time()

paste("Job done in ",t2-t1)
saveRDS(res,"UDpipe/libera_2013_2020_parsed")
```

Le travail a été fait en 1.2 heures ce qui est logique, le fichier étant plus petit. Mais il fait tout de même 4.7 millions de lignes (tokens). 
N.B. Il y a des problèmes avec le texte de Libé...



